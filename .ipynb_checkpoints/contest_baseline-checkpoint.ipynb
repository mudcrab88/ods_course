{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import datetime\n",
    "import xgboost\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import data_helpers as dh\n",
    "import data_iter1 as di\n",
    "import submit_report as rep\n",
    "import model_utils as mu\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Test\\ods_course\\data_helpers.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data['date'] = pd.to_datetime(data.timestamp, unit='s')\n",
      "D:\\Test\\ods_course\\data_helpers.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data['day'] = data.date.dt.date\n"
     ]
    }
   ],
   "source": [
    "# загрузка данных\n",
    "events  = pd.read_csv('event_data_train.csv')\n",
    "submissions = pd.read_csv('submissions_data_train.csv')\n",
    "\n",
    "# разделение данных для обучения на train и test\n",
    "_ = dh.split_events_submissions(events, submissions, test_size=0.3)\n",
    "events_train_orig, events_test_orig, submissions_train_orig, submissions_test_orig = _\n",
    "\n",
    "# подготовка данных\n",
    "X_train, y_train = di.get_x_y(events_train_orig, submissions_train_orig)\n",
    "X_test, y_test = di.get_x_y(events_test_orig, submissions_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19234, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.append(X_test)\n",
    "y = y_train.append(y_test)\n",
    "user_min_time = events.groupby('user_id', as_index=False).agg({'timestamp':'min'})\n",
    "user_min_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: 'user_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong</th>\n",
       "      <th>discovered</th>\n",
       "      <th>passed</th>\n",
       "      <th>started_attempt</th>\n",
       "      <th>viewed</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>2016-09-02 14:44:24</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>2017-12-27 14:02:44</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>2015-06-15</td>\n",
       "      <td>2015-06-15 08:54:36</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>2016-06-17 09:46:49</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>109</td>\n",
       "      <td>84</td>\n",
       "      <td>37</td>\n",
       "      <td>154</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>2016-12-01 14:43:47</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct  wrong  discovered  passed  started_attempt  viewed         day  \\\n",
       "0      0.0    0.0           1       0                0       1  2016-09-02   \n",
       "1      2.0    0.0           9       9                2       9  2017-12-27   \n",
       "2      4.0    4.0          15      15                4      20  2015-06-15   \n",
       "3      2.0    2.0           1       1                0       1  2016-06-17   \n",
       "4      9.0   21.0         109      84               37     154  2016-12-01   \n",
       "\n",
       "                 date  weekday  year  month  hour  \n",
       "0 2016-09-02 14:44:24        4  2016      9    14  \n",
       "1 2017-12-27 14:02:44        2  2017     12    14  \n",
       "2 2015-06-15 08:54:36        0  2015      6     8  \n",
       "3 2016-06-17 09:46:49        4  2016      6     9  \n",
       "4 2016-12-01 14:43:47        3  2016     12    14  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['user_id'] = X.index\n",
    "X = X.merge(user_min_time[['user_id','timestamp']], how='outer')\n",
    "X['date'] = pd.to_datetime(X['timestamp'], unit = 's')\n",
    "X['day'] = X['date'].dt.date\n",
    "X['weekday'] = X['date'].dt.dayofweek\n",
    "X = X.drop('user_id', axis=1)\n",
    "X = X.drop('timestamp', axis=1)\n",
    "X['year'] = X['date'].dt.year\n",
    "X['month'] = X['date'].dt.month\n",
    "X['hour'] = X['date'].dt.hour\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong</th>\n",
       "      <th>discovered</th>\n",
       "      <th>passed</th>\n",
       "      <th>started_attempt</th>\n",
       "      <th>viewed</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>hour21</th>\n",
       "      <th>hour22</th>\n",
       "      <th>hour23</th>\n",
       "      <th>weekday0</th>\n",
       "      <th>weekday1</th>\n",
       "      <th>weekday2</th>\n",
       "      <th>weekday3</th>\n",
       "      <th>weekday4</th>\n",
       "      <th>weekday5</th>\n",
       "      <th>weekday6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>2016-09-02 14:44:24</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>2017-12-27 14:02:44</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>2015-06-15</td>\n",
       "      <td>2015-06-15 08:54:36</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>2016-06-17 09:46:49</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>109</td>\n",
       "      <td>84</td>\n",
       "      <td>37</td>\n",
       "      <td>154</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>2016-12-01 14:43:47</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct  wrong  discovered  passed  started_attempt  viewed         day  \\\n",
       "0      0.0    0.0           1       0                0       1  2016-09-02   \n",
       "1      2.0    0.0           9       9                2       9  2017-12-27   \n",
       "2      4.0    4.0          15      15                4      20  2015-06-15   \n",
       "3      2.0    2.0           1       1                0       1  2016-06-17   \n",
       "4      9.0   21.0         109      84               37     154  2016-12-01   \n",
       "\n",
       "                 date  weekday  year    ...     hour21  hour22  hour23  \\\n",
       "0 2016-09-02 14:44:24        4  2016    ...        0.0     0.0     0.0   \n",
       "1 2017-12-27 14:02:44        2  2017    ...        0.0     0.0     0.0   \n",
       "2 2015-06-15 08:54:36        0  2015    ...        0.0     0.0     0.0   \n",
       "3 2016-06-17 09:46:49        4  2016    ...        0.0     0.0     0.0   \n",
       "4 2016-12-01 14:43:47        3  2016    ...        0.0     0.0     0.0   \n",
       "\n",
       "   weekday0  weekday1  weekday2  weekday3  weekday4  weekday5  weekday6  \n",
       "0       0.0       0.0       0.0       0.0       1.0       0.0       0.0  \n",
       "1       0.0       0.0       1.0       0.0       0.0       0.0       0.0  \n",
       "2       1.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "3       0.0       0.0       0.0       0.0       1.0       0.0       0.0  \n",
       "4       0.0       0.0       0.0       1.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "new_features = ohe.fit_transform(X['year'].values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['year' + str(i) for i in range(new_features.shape[1])])\n",
    "X = pd.concat([X, tmp], axis=1)\n",
    "new_features = ohe.fit_transform(X['month'].values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['month' + str(i) for i in range(new_features.shape[1])])\n",
    "X = pd.concat([X, tmp], axis=1)\n",
    "new_features = ohe.fit_transform(X['hour'].values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['hour' + str(i) for i in range(new_features.shape[1])])\n",
    "X = pd.concat([X, tmp], axis=1)\n",
    "new_features = ohe.fit_transform(X['weekday'].values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['weekday' + str(i) for i in range(new_features.shape[1])])\n",
    "X = pd.concat([X, tmp], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('day', axis=1)\n",
    "X = X.drop('date', axis=1)\n",
    "X = X.drop('weekday', axis=1)\n",
    "X = X.drop('month', axis=1)\n",
    "X = X.drop('year', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=10,\n",
       "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=2, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc на test 0.9298772125116344\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=2, \n",
    "                            min_samples_leaf=10, min_samples_split=10, \n",
    "                            class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "pred_proba = rf.predict_proba(X_test)\n",
    "roc_score = roc_auc_score(y_test, pred_proba[:, 1])\n",
    "print('roc на test', roc_score)\n",
    "# должны получить roc 0.92  +- 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>correct</th>\n",
       "      <td>0.307779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passed</th>\n",
       "      <td>0.158638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discovered</th>\n",
       "      <td>0.128893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewed</th>\n",
       "      <td>0.128383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrong</th>\n",
       "      <td>0.101947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>started_attempt</th>\n",
       "      <td>0.093377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0.013533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month5</th>\n",
       "      <td>0.011646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year0</th>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year3</th>\n",
       "      <td>0.003575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year1</th>\n",
       "      <td>0.003022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year2</th>\n",
       "      <td>0.002980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday0</th>\n",
       "      <td>0.002810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month6</th>\n",
       "      <td>0.002795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month8</th>\n",
       "      <td>0.002733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   weight\n",
       "correct          0.307779\n",
       "passed           0.158638\n",
       "discovered       0.128893\n",
       "viewed           0.128383\n",
       "wrong            0.101947\n",
       "started_attempt  0.093377\n",
       "hour             0.013533\n",
       "month5           0.011646\n",
       "year0            0.003602\n",
       "year3            0.003575\n",
       "year1            0.003022\n",
       "year2            0.002980\n",
       "weekday0         0.002810\n",
       "month6           0.002795\n",
       "month8           0.002733"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# важность фич\n",
    "fimp = mu.get_feature_importances_df(rf.feature_importances_, X_train.columns)\n",
    "fimp.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score 0.9255371019308377\n"
     ]
    }
   ],
   "source": [
    "# значение к метрике на кроссвалидации коррелирует к метрике на степике\n",
    "\n",
    "rfcv = RandomForestClassifier(**rf.get_params())\n",
    "\n",
    "cv_scores = cross_val_score(rfcv, X_train, y_train, scoring='roc_auc', cv=10, n_jobs=-1)\n",
    "mean_cv_scores = np.mean(cv_scores)\n",
    "print ('mean score', mean_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SUBMIT_NUM = 6\n",
    "\n",
    "events_pred  = pd.read_csv('events_data_test.csv')\n",
    "submissions_pred = pd.read_csv('submission_data_test.csv')\n",
    "X_pred , _ = di.get_x_y(events_pred, submissions_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: 'user_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong</th>\n",
       "      <th>discovered</th>\n",
       "      <th>passed</th>\n",
       "      <th>started_attempt</th>\n",
       "      <th>viewed</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-18</td>\n",
       "      <td>2018-06-18 14:21:47</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2019-01-07 19:30:07</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>2018-08-18 09:49:16</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2018-09-19</td>\n",
       "      <td>2018-09-19 09:14:34</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>35</td>\n",
       "      <td>105</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>2018-07-31 10:52:34</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct  wrong  discovered  passed  started_attempt  viewed         day  \\\n",
       "0      0.0    0.0           1       1                0       1  2018-06-18   \n",
       "1      0.0    0.0           1       1                0       1  2019-01-07   \n",
       "2      0.0    0.0           2       2                0       6  2018-08-18   \n",
       "3      1.0    0.0          11       9                4      14  2018-09-19   \n",
       "4     29.0   36.0          70      70               35     105  2018-07-31   \n",
       "\n",
       "                 date  weekday  year  month  hour  \n",
       "0 2018-06-18 14:21:47        0  2018      6    14  \n",
       "1 2019-01-07 19:30:07        0  2019      1    19  \n",
       "2 2018-08-18 09:49:16        5  2018      8     9  \n",
       "3 2018-09-19 09:14:34        2  2018      9     9  \n",
       "4 2018-07-31 10:52:34        1  2018      7    10  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_min_time_pred = events_pred.groupby('user_id', as_index=False).agg({'timestamp':'min'})\n",
    "X_pred['user_id'] = X_pred.index\n",
    "X_pred = X_pred.merge(user_min_time_pred[['user_id','timestamp']], how='outer')\n",
    "X_pred['date'] = pd.to_datetime(X_pred['timestamp'], unit = 's')\n",
    "X_pred['day'] = X_pred['date'].dt.date\n",
    "X_pred['weekday'] = X_pred['date'].dt.dayofweek\n",
    "X_pred = X_pred.drop('user_id', axis=1)\n",
    "X_pred = X_pred.drop('timestamp', axis=1)\n",
    "X_pred['year'] = X_pred['date'].dt.year\n",
    "X_pred['month'] = X_pred['date'].dt.month\n",
    "X_pred['hour'] = X_pred['date'].dt.hour\n",
    "X_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong</th>\n",
       "      <th>discovered</th>\n",
       "      <th>passed</th>\n",
       "      <th>started_attempt</th>\n",
       "      <th>viewed</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>hour21</th>\n",
       "      <th>hour22</th>\n",
       "      <th>hour23</th>\n",
       "      <th>weekday0</th>\n",
       "      <th>weekday1</th>\n",
       "      <th>weekday2</th>\n",
       "      <th>weekday3</th>\n",
       "      <th>weekday4</th>\n",
       "      <th>weekday5</th>\n",
       "      <th>weekday6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-18</td>\n",
       "      <td>2018-06-18 14:21:47</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2019-01-07 19:30:07</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>2018-08-18 09:49:16</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2018-09-19</td>\n",
       "      <td>2018-09-19 09:14:34</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>35</td>\n",
       "      <td>105</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>2018-07-31 10:52:34</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct  wrong  discovered  passed  started_attempt  viewed         day  \\\n",
       "0      0.0    0.0           1       1                0       1  2018-06-18   \n",
       "1      0.0    0.0           1       1                0       1  2019-01-07   \n",
       "2      0.0    0.0           2       2                0       6  2018-08-18   \n",
       "3      1.0    0.0          11       9                4      14  2018-09-19   \n",
       "4     29.0   36.0          70      70               35     105  2018-07-31   \n",
       "\n",
       "                 date  weekday  year    ...     hour21  hour22  hour23  \\\n",
       "0 2018-06-18 14:21:47        0  2018    ...        0.0     0.0     0.0   \n",
       "1 2019-01-07 19:30:07        0  2019    ...        0.0     0.0     0.0   \n",
       "2 2018-08-18 09:49:16        5  2018    ...        0.0     0.0     0.0   \n",
       "3 2018-09-19 09:14:34        2  2018    ...        0.0     0.0     0.0   \n",
       "4 2018-07-31 10:52:34        1  2018    ...        0.0     0.0     0.0   \n",
       "\n",
       "   weekday0  weekday1  weekday2  weekday3  weekday4  weekday5  weekday6  \n",
       "0       1.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "1       1.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2       0.0       0.0       0.0       0.0       0.0       1.0       0.0  \n",
       "3       0.0       0.0       1.0       0.0       0.0       0.0       0.0  \n",
       "4       0.0       1.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "new_features = ohe.fit_transform(X_pred['year'].values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['year' + str(i) for i in range(new_features.shape[1])])\n",
    "X_pred = pd.concat([X_pred, tmp], axis=1)\n",
    "new_features = ohe.fit_transform(X_pred['month'].values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['month' + str(i) for i in range(new_features.shape[1])])\n",
    "X_pred = pd.concat([X_pred, tmp], axis=1)\n",
    "new_features = ohe.fit_transform(X_pred['hour'].values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['hour' + str(i) for i in range(new_features.shape[1])])\n",
    "X_pred = pd.concat([X_pred, tmp], axis=1)\n",
    "new_features = ohe.fit_transform(X_pred['weekday'].values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['weekday' + str(i) for i in range(new_features.shape[1])])\n",
    "X_pred = pd.concat([X_pred, tmp], axis=1)\n",
    "X_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6184, 49)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = X_pred.drop('day', axis=1)\n",
    "X_pred = X_pred.drop('date', axis=1)\n",
    "X_pred = X_pred.drop('weekday', axis=1)\n",
    "X_pred = X_pred.drop('month', axis=1)\n",
    "X_pred = X_pred.drop('year', axis=1)\n",
    "X_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 54 and input n_features is 49 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-a3a15f8f1724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrep_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mrep_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mX_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Прогноз сохранен в файл '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSUBMIT_NUM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    386\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 54 and input n_features is 49 "
     ]
    }
   ],
   "source": [
    "pred_proba = rf.predict_proba(X_pred)[:, 1]\n",
    "rep_df = rep.create_report(X_pred.index, pred_proba)\n",
    "assert rep_df.user_id.nunique() == X_pred.index.nunique()\n",
    "print ('Прогноз сохранен в файл ', rep.save_report(rep_df, SUBMIT_NUM))\n",
    "\n",
    "print ('Распределение \"вероятностей\" модели')\n",
    "pd.cut(pred_proba, 10).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2688 candidates, totalling 13440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 11242 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12792 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 13440 out of 13440 | elapsed: 14.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_features': [1, 2, 3, 4, 5, 6, 7], 'n_estimators': [18, 19, 20, 21], 'max_depth': [7, 8, 9, 10], 'min_samples_leaf': [1, 2, 3, 4], 'min_samples_split': [6, 7, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "parametrs_rf = {'criterion': ['gini', 'entropy'],\n",
    "            'max_features' : [1, 2, 3, 4, 5, 6, 7],\n",
    "            'n_estimators': [18, 19, 20, 21],\n",
    "            'max_depth': [7, 8, 9, 10],\n",
    "            'min_samples_leaf': [1, 2, 3, 4],\n",
    "            'min_samples_split': [6, 7, 8]}\n",
    "grid_search_cv_clf = GridSearchCV(estimator=rf, param_grid=parametrs_rf, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search_cv_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=7, max_features=5, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=7,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=21, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc на test 0.9330574833464914\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid_search_cv_clf.best_estimator_\n",
    "pred_proba = best_rf.predict_proba(X_test_scaled)\n",
    "roc_score = roc_auc_score(y_test, pred_proba[:, 1])\n",
    "print('roc на test', roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score 0.9233465900694563\n"
     ]
    }
   ],
   "source": [
    "# значение к метрике на кроссвалидации коррелирует к метрике на степике\n",
    "\n",
    "rfcv = RandomForestClassifier(**best_rf.get_params())\n",
    "cv_scores = cross_val_score(rfcv, X_train_scaled, y_train, scoring='roc_auc', cv=10, n_jobs=-1)\n",
    "mean_cv_scores = np.mean(cv_scores)\n",
    "print ('mean score', mean_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прогноз сохранен в файл  ./reports/predict_2019-05-21_submit_5.csv\n",
      "Распределение \"вероятностей\" модели\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.001, 0.1]    3362\n",
       "(0.1, 0.2]        401\n",
       "(0.2, 0.3]        735\n",
       "(0.3, 0.4]        391\n",
       "(0.4, 0.5]        208\n",
       "(0.5, 0.6]        169\n",
       "(0.6, 0.7]        187\n",
       "(0.7, 0.8]        144\n",
       "(0.8, 0.9]        124\n",
       "(0.9, 1.0]        463\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBMIT_NUM = 5\n",
    "\n",
    "events_pred  = pd.read_csv('events_data_test.csv')\n",
    "submissions_pred = pd.read_csv('submission_data_test.csv')\n",
    "X_pred , _ = di.get_x_y(events_pred, submissions_pred)\n",
    "X_pred_scaled = StandardScaler().fit_transform(X_pred)\n",
    "pred_proba = best_rf.predict_proba(X_pred_scaled)[:, 1]\n",
    "rep_df = rep.create_report(X_pred.index, pred_proba)\n",
    "assert rep_df.user_id.nunique() == X_pred.index.nunique()\n",
    "print ('Прогноз сохранен в файл ', rep.save_report(rep_df, SUBMIT_NUM))\n",
    "\n",
    "print ('Распределение \"вероятностей\" модели')\n",
    "pd.cut(pred_proba, 10).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "X_test_scaled = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgboost.XGBClassifier()\n",
    "test_params = {\n",
    "  \"n_estimators\" : [125, 130, 135],\n",
    " \"learning_rate\"    : [0.02, 0.04, 0.05],\n",
    " \"max_depth\"        : [3, 4],\n",
    " \"min_child_weight\" : [ 1, 2, 4]\n",
    "}\n",
    "model = GridSearchCV(estimator = xgb_model,param_grid = test_params, n_jobs=-1, verbose=10, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [125, 130, 135], 'learning_rate': [0.02, 0.04, 0.05], 'max_depth': [3, 4], 'min_child_weight': [1, 2, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.04, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 130}\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train)\n",
    "print (model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc на test 0.9327440493248386\n"
     ]
    }
   ],
   "source": [
    "best_xgb = model.best_estimator_\n",
    "pred_proba = best_xgb.predict_proba(X_test_scaled)\n",
    "roc_score = roc_auc_score(y_test, pred_proba[:, 1])\n",
    "print('roc на test', roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong</th>\n",
       "      <th>discovered</th>\n",
       "      <th>passed</th>\n",
       "      <th>started_attempt</th>\n",
       "      <th>viewed</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         correct  wrong  discovered  passed  started_attempt  viewed  day\n",
       "user_id                                                                  \n",
       "1            0.0    0.0           1       0                0       1    1\n",
       "2            2.0    0.0           9       9                2       9    1\n",
       "3            4.0    4.0          15      15                4      20    1\n",
       "5            2.0    2.0           1       1                0       1    1\n",
       "7            0.0    0.0           1       1                0       1    1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
