{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import datetime\n",
    "import xgboost\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import data_helpers as dh\n",
    "import data_iter1 as di\n",
    "import submit_report as rep\n",
    "import model_utils as mu\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Test\\ods_course\\data_helpers.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data['date'] = pd.to_datetime(data.timestamp, unit='s')\n",
      "D:\\Test\\ods_course\\data_helpers.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data['day'] = data.date.dt.date\n"
     ]
    }
   ],
   "source": [
    "# загрузка данных\n",
    "events  = pd.read_csv('event_data_train.csv')\n",
    "submissions = pd.read_csv('submissions_data_train.csv')\n",
    "\n",
    "# разделение данных для обучения на train и test\n",
    "_ = dh.split_events_submissions(events, submissions, test_size=0.3)\n",
    "events_train_orig, events_test_orig, submissions_train_orig, submissions_test_orig = _\n",
    "\n",
    "# подготовка данных\n",
    "X_train, y_train = di.get_x_y(events_train_orig, submissions_train_orig)\n",
    "X_test, y_test = di.get_x_y(events_test_orig, submissions_test_orig)\n",
    "\n",
    "#загрузка данных для предсказаний\n",
    "events_pred  = pd.read_csv('events_data_test.csv')\n",
    "submissions_pred = pd.read_csv('submission_data_test.csv')\n",
    "X_pred , _ = di.get_x_y(events_pred, submissions_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: 'user_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19234, 11)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Подготовка данных для тренировки модели\n",
    "X = X_train.append(X_test)\n",
    "y = y_train.append(y_test)\n",
    "user_min_time = events.groupby('user_id', as_index=False).agg({'timestamp':'min'})\n",
    "X['user_id'] = X.index\n",
    "X = X.merge(user_min_time[['user_id','timestamp']], how='outer')\n",
    "X['date'] = pd.to_datetime(X['timestamp'], unit = 's')\n",
    "X['day'] = X['date'].dt.date\n",
    "X['weekday'] = X['date'].dt.dayofweek\n",
    "#X = X.drop('user_id', axis=1)\n",
    "X = X.drop('timestamp', axis=1)\n",
    "X['year'] = X['date'].dt.year\n",
    "X['month'] = X['date'].dt.month\n",
    "X['hour'] = X['date'].dt.hour\n",
    "X = X.drop('day', axis=1)\n",
    "X = X.drop('date', axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: 'user_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6184, 11)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#подготовка данных для предсказаний\n",
    "user_min_time_pred = events_pred.groupby('user_id', as_index=False).agg({'timestamp':'min'})\n",
    "X_pred['user_id'] = X_pred.index\n",
    "X_pred = X_pred.merge(user_min_time_pred[['user_id','timestamp']], how='outer')\n",
    "X_pred['date'] = pd.to_datetime(X_pred['timestamp'], unit = 's')\n",
    "X_pred['day'] = X_pred['date'].dt.date\n",
    "X_pred['weekday'] = X_pred['date'].dt.dayofweek\n",
    "X_pred = X_pred.drop('timestamp', axis=1)\n",
    "X_pred['year'] = X_pred['date'].dt.year\n",
    "X_pred['month'] = X_pred['date'].dt.month\n",
    "X_pred['hour'] = X_pred['date'].dt.hour\n",
    "X_pred = X_pred.drop('day', axis=1)\n",
    "X_pred = X_pred.drop('date', axis=1)\n",
    "X_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#данные для OneHotEncoder\n",
    "year = X['year'].append(X_pred['year'])\n",
    "month = X['month'].append(X_pred['month'])\n",
    "hour = X['hour'].append(X_pred['hour'])\n",
    "weekday = X['weekday'].append(X_pred['weekday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25418, 19234]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-f6e0b9256aeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2182\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2184\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2186\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25418, 19234]"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "new_features = ohe.fit_transform(year.values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['year' + str(i) for i in range(new_features.shape[1])])\n",
    "X = pd.concat([X, tmp], axis=1)\n",
    "new_features = ohe.fit_transform(month.values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['month' + str(i) for i in range(new_features.shape[1])])\n",
    "X = pd.concat([X, tmp], axis=1)\n",
    "new_features = ohe.fit_transform(hour.values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['hour' + str(i) for i in range(new_features.shape[1])])\n",
    "X = pd.concat([X, tmp], axis=1)\n",
    "new_features = ohe.fit_transform(weekday.values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['weekday' + str(i) for i in range(new_features.shape[1])])\n",
    "X = pd.concat([X, tmp], axis=1)\n",
    "X = X.set_index('user_id')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['correct', 'passed','discovered', 'wrong', 'viewed', 'started_attempt', 'hour', 'month', 'weekday', 'year']\n",
    "X_train = X_train[cols]\n",
    "X_test = X_test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=10,\n",
       "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=2, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc на test 0.9275756878612602\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=2, \n",
    "                            min_samples_leaf=10, min_samples_split=10, \n",
    "                            class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "pred_proba = rf.predict_proba(X_test)\n",
    "roc_score = roc_auc_score(y_test, pred_proba[:, 1])\n",
    "print('roc на test', roc_score)\n",
    "# должны получить roc 0.92  +- 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>correct</th>\n",
       "      <td>0.371892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passed</th>\n",
       "      <td>0.179072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discovered</th>\n",
       "      <td>0.137486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewed</th>\n",
       "      <td>0.113825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrong</th>\n",
       "      <td>0.064532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>started_attempt</th>\n",
       "      <td>0.051911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0.026720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.024487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>0.016251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.013826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   weight\n",
       "correct          0.371892\n",
       "passed           0.179072\n",
       "discovered       0.137486\n",
       "viewed           0.113825\n",
       "wrong            0.064532\n",
       "started_attempt  0.051911\n",
       "hour             0.026720\n",
       "month            0.024487\n",
       "weekday          0.016251\n",
       "year             0.013826"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# важность фич\n",
    "fimp = mu.get_feature_importances_df(rf.feature_importances_, X_train.columns)\n",
    "fimp.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score 0.9260628639264479\n"
     ]
    }
   ],
   "source": [
    "# значение к метрике на кроссвалидации коррелирует к метрике на степике\n",
    "rfcv = RandomForestClassifier(**rf.get_params())\n",
    "cv_scores = cross_val_score(rfcv, X_train, y_train, scoring='roc_auc', cv=10, n_jobs=-1)\n",
    "mean_cv_scores = np.mean(cv_scores)\n",
    "print ('mean score', mean_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SUBMIT_NUM = 7\n",
    "events_pred  = pd.read_csv('events_data_test.csv')\n",
    "submissions_pred = pd.read_csv('submission_data_test.csv')\n",
    "X_pred , _ = di.get_x_y(events_pred, submissions_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: 'user_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong</th>\n",
       "      <th>discovered</th>\n",
       "      <th>passed</th>\n",
       "      <th>started_attempt</th>\n",
       "      <th>viewed</th>\n",
       "      <th>user_id</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>35</td>\n",
       "      <td>105</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct  wrong  discovered  passed  started_attempt  viewed  user_id  \\\n",
       "0      0.0    0.0           1       1                0       1        4   \n",
       "1      0.0    0.0           1       1                0       1        6   \n",
       "2      0.0    0.0           2       2                0       6       10   \n",
       "3      1.0    0.0          11       9                4      14       12   \n",
       "4     29.0   36.0          70      70               35     105       13   \n",
       "\n",
       "   weekday  year  month  hour  \n",
       "0        0  2018      6    14  \n",
       "1        0  2019      1    19  \n",
       "2        5  2018      8     9  \n",
       "3        2  2018      9     9  \n",
       "4        1  2018      7    10  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_min_time_pred = events_pred.groupby('user_id', as_index=False).agg({'timestamp':'min'})\n",
    "X_pred['user_id'] = X_pred.index\n",
    "X_pred = X_pred.merge(user_min_time_pred[['user_id','timestamp']], how='outer')\n",
    "X_pred['date'] = pd.to_datetime(X_pred['timestamp'], unit = 's')\n",
    "X_pred['day'] = X_pred['date'].dt.date\n",
    "X_pred['weekday'] = X_pred['date'].dt.dayofweek\n",
    "X_pred = X_pred.drop('timestamp', axis=1)\n",
    "X_pred['year'] = X_pred['date'].dt.year\n",
    "X_pred['month'] = X_pred['date'].dt.month\n",
    "X_pred['hour'] = X_pred['date'].dt.hour\n",
    "X_pred = X_pred.drop('day', axis=1)\n",
    "X_pred = X_pred.drop('date', axis=1)\n",
    "X_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6184, 52)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "new_features = ohe.fit_transform(X_pred['year'].values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['year' + str(i) for i in range(new_features.shape[1])])\n",
    "X_pred = pd.concat([X_pred, tmp], axis=1)\n",
    "new_features = ohe.fit_transform(X_pred['month'].values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['month' + str(i) for i in range(new_features.shape[1])])\n",
    "X_pred = pd.concat([X_pred, tmp], axis=1)\n",
    "new_features = ohe.fit_transform(X_pred['hour'].values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['hour' + str(i) for i in range(new_features.shape[1])])\n",
    "X_pred = pd.concat([X_pred, tmp], axis=1)\n",
    "new_features = ohe.fit_transform(X_pred['weekday'].values.reshape(-1,1))\n",
    "tmp = pd.DataFrame(new_features, columns=['weekday' + str(i) for i in range(new_features.shape[1])])\n",
    "X_pred = pd.concat([X_pred, tmp], axis=1)\n",
    "X_pred = X_pred.set_index('user_id')\n",
    "X_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = X_pred[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прогноз сохранен в файл  predict_2019-05-22_submit_7.csv\n",
      "Распределение \"вероятностей\" модели\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.001, 0.1]    3312\n",
       "(0.1, 0.2]        178\n",
       "(0.2, 0.3]        360\n",
       "(0.3, 0.4]        503\n",
       "(0.4, 0.5]        350\n",
       "(0.5, 0.6]        239\n",
       "(0.6, 0.7]        301\n",
       "(0.7, 0.8]        273\n",
       "(0.8, 0.9]        109\n",
       "(0.9, 1.0]        559\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = rf.predict_proba(X_pred)[:, 1]\n",
    "rep_df = rep.create_report(X_pred.index, pred_proba)\n",
    "assert rep_df.user_id.nunique() == X_pred.index.nunique()\n",
    "print ('Прогноз сохранен в файл ', rep.save_report(rep_df, SUBMIT_NUM))\n",
    "\n",
    "print ('Распределение \"вероятностей\" модели')\n",
    "pd.cut(pred_proba, 10).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_features': [9, 10], 'n_estimators': [15, 20, 50], 'max_depth': [4, 5, 6], 'min_samples_leaf': [1, 2, 3], 'min_samples_split': [15, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "parametrs_rf = {'criterion': ['gini', 'entropy'],\n",
    "            'max_features' : [9, 10],\n",
    "            'n_estimators': [15, 20, 50],\n",
    "            'max_depth': [4, 5, 6],\n",
    "            'min_samples_leaf': [1, 2, 3],\n",
    "            'min_samples_split': [15, 20]}\n",
    "grid_search_cv_clf = GridSearchCV(estimator=rf, param_grid=parametrs_rf, cv=5, n_jobs=-1, verbose=1, scoring='roc_auc')\n",
    "grid_search_cv_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=6, max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=15,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = grid_search_cv_clf.best_estimator_\n",
    "best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc на test 0.9297312697356405\n"
     ]
    }
   ],
   "source": [
    "pred_proba = best_rf.predict_proba(X_test)\n",
    "roc_score = roc_auc_score(y_test, pred_proba[:, 1])\n",
    "print('roc на test', roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score 0.9266923491547825\n"
     ]
    }
   ],
   "source": [
    "# значение к метрике на кроссвалидации коррелирует к метрике на степике\n",
    "\n",
    "rfcv = RandomForestClassifier(**best_rf.get_params())\n",
    "cv_scores = cross_val_score(rfcv, X_train, y_train, scoring='roc_auc', cv=10, n_jobs=-1)\n",
    "mean_cv_scores = np.mean(cv_scores)\n",
    "print ('mean score', mean_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прогноз сохранен в файл  predict_2019-05-22_submit_7.csv\n",
      "Распределение \"вероятностей\" модели\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.000881, 0.1]    3419\n",
       "(0.1, 0.2]           478\n",
       "(0.2, 0.3]           878\n",
       "(0.3, 0.4]           126\n",
       "(0.4, 0.5]           280\n",
       "(0.5, 0.6]           303\n",
       "(0.6, 0.7]            69\n",
       "(0.7, 0.8]            34\n",
       "(0.8, 0.9]           149\n",
       "(0.9, 1.0]           448\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBMIT_NUM = 7\n",
    "\n",
    "pred_proba = best_rf.predict_proba(X_pred)[:, 1]\n",
    "rep_df = rep.create_report(X_pred.index, pred_proba)\n",
    "assert rep_df.user_id.nunique() == X_pred.index.nunique()\n",
    "print ('Прогноз сохранен в файл ', rep.save_report(rep_df, SUBMIT_NUM))\n",
    "\n",
    "print ('Распределение \"вероятностей\" модели')\n",
    "pd.cut(pred_proba, 10).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "X_test_scaled = StandardScaler().fit_transform(X_test)\n",
    "X_pred_scaled = StandardScaler().fit_transform(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgboost.XGBClassifier()\n",
    "test_params = {\n",
    "  \"n_estimators\" : [90, 100, 110],\n",
    " \"learning_rate\"    : [0.02, 0.04, 0.05],\n",
    " \"max_depth\"        : [3, 4, 5],\n",
    " \"min_child_weight\" : [ 1, 2, 4]\n",
    "}\n",
    "model = GridSearchCV(estimator = xgb_model,param_grid = test_params, n_jobs=-1, verbose=10, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   49.1s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [90, 100, 110], 'learning_rate': [0.02, 0.04, 0.05], 'max_depth': [3, 4, 5], 'min_child_weight': [1, 2, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train)\n",
    "print (model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc на test 0.9320736692623023\n"
     ]
    }
   ],
   "source": [
    "best_xgb = model.best_estimator_\n",
    "pred_proba = best_xgb.predict_proba(X_test)\n",
    "roc_score = roc_auc_score(y_test, pred_proba[:, 1])\n",
    "print('roc на test', roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=4, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прогноз сохранен в файл  predict_2019-05-22_submit_8.csv\n",
      "Распределение \"вероятностей\" модели\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00345, 0.104]    3690\n",
       "(0.104, 0.203]      1048\n",
       "(0.203, 0.302]       295\n",
       "(0.302, 0.401]       244\n",
       "(0.401, 0.5]         189\n",
       "(0.5, 0.599]          77\n",
       "(0.599, 0.698]        29\n",
       "(0.698, 0.797]        93\n",
       "(0.797, 0.897]        81\n",
       "(0.897, 0.996]       438\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBMIT_NUM = 8\n",
    "\n",
    "pred_proba = best_xgb.predict_proba(X_pred)[:, 1]\n",
    "rep_df = rep.create_report(X_pred.index, pred_proba)\n",
    "assert rep_df.user_id.nunique() == X_pred.index.nunique()\n",
    "print ('Прогноз сохранен в файл ', rep.save_report(rep_df, SUBMIT_NUM))\n",
    "\n",
    "print ('Распределение \"вероятностей\" модели')\n",
    "pd.cut(pred_proba, 10).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1        2016\n",
       "2        2017\n",
       "5        2016\n",
       "7        2018\n",
       "9        2017\n",
       "14       2015\n",
       "18       2015\n",
       "20       2015\n",
       "22       2017\n",
       "26       2016\n",
       "28       2015\n",
       "30       2016\n",
       "31       2017\n",
       "32       2017\n",
       "33       2015\n",
       "36       2018\n",
       "38       2015\n",
       "44       2017\n",
       "46       2015\n",
       "50       2015\n",
       "52       2015\n",
       "53       2018\n",
       "54       2017\n",
       "57       2018\n",
       "59       2016\n",
       "60       2017\n",
       "64       2017\n",
       "65       2015\n",
       "67       2017\n",
       "68       2015\n",
       "         ... \n",
       "26696    2018\n",
       "26698    2018\n",
       "26699    2018\n",
       "26701    2018\n",
       "26706    2018\n",
       "26710    2018\n",
       "26713    2018\n",
       "26720    2018\n",
       "26721    2018\n",
       "26724    2018\n",
       "26729    2018\n",
       "26730    2018\n",
       "26735    2018\n",
       "26736    2018\n",
       "26738    2018\n",
       "26743    2018\n",
       "26744    2018\n",
       "26745    2018\n",
       "26748    2018\n",
       "26758    2018\n",
       "26768    2018\n",
       "26770    2018\n",
       "26775    2018\n",
       "26780    2018\n",
       "26785    2019\n",
       "26791    2018\n",
       "26795    2018\n",
       "26796    2018\n",
       "26799    2018\n",
       "26800    2018\n",
       "Name: year, Length: 25418, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['correct', 'wrong', 'discovered', 'passed', 'started_attempt', 'viewed',\n",
       "       'weekday', 'year', 'month', 'hour', 'year0', 'year1', 'year2', 'year3',\n",
       "       'month0', 'month1', 'month2', 'month3', 'month4', 'month5', 'month6',\n",
       "       'month7', 'month8', 'month9', 'month10', 'month11', 'hour0', 'hour1',\n",
       "       'hour2', 'hour3', 'hour4', 'hour5', 'hour6', 'hour7', 'hour8', 'hour9',\n",
       "       'hour10', 'hour11', 'hour12', 'hour13', 'hour14', 'hour15', 'hour16',\n",
       "       'hour17', 'hour18', 'hour19', 'hour20', 'hour21', 'hour22', 'hour23',\n",
       "       'weekday0', 'weekday1', 'weekday2', 'weekday3', 'weekday4', 'weekday5',\n",
       "       'weekday6', 'correct', 'passed', 'discovered', 'wrong', 'viewed',\n",
       "       'started_attempt', 'hour', 'month', 'weekday', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
